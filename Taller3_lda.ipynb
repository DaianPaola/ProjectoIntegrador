{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n",
    "\n",
    "Hernán Sepúlveda,  \n",
    "Daian Paola Fajardo,   \n",
    "Juan Carlos Agudelo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import nltk; nltk.download('stopwords')\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_name(author):\n",
    "    middle_name = \" \".join(author['middle'])\n",
    "    \n",
    "    if author['middle']:\n",
    "        return \" \".join([author['first'], middle_name, author['last']])\n",
    "    else:\n",
    "        return \" \".join([author['first'], author['last']])\n",
    "    \n",
    "def format_affiliation(affiliation):\n",
    "    text = []\n",
    "    location = affiliation.get('location')\n",
    "    if location:\n",
    "        text.extend(list(affiliation['location'].values()))\n",
    "    \n",
    "    institution = affiliation.get('institution')\n",
    "    if institution:\n",
    "        text = [institution] + text\n",
    "    return \", \".join(text)\n",
    "\n",
    "def format_authors(authors, with_affiliation=False):\n",
    "    name_ls = []\n",
    "    \n",
    "    for author in authors:\n",
    "        name = format_name(author)\n",
    "        if with_affiliation:\n",
    "            affiliation = format_affiliation(author['affiliation'])\n",
    "            if affiliation:\n",
    "                name_ls.append(f\"{name} ({affiliation})\")\n",
    "            else:\n",
    "                name_ls.append(name)\n",
    "        else:\n",
    "            name_ls.append(name)\n",
    "    \n",
    "    return \", \".join(name_ls)\n",
    "\n",
    "def format_body(body_text):\n",
    "    texts = [(di['section'], di['text']) for di in body_text]\n",
    "    texts_di = {di['section']: \"\" for di in body_text}\n",
    "    \n",
    "    for section, text in texts:\n",
    "        texts_di[section] += text\n",
    "\n",
    "    body = \"\"\n",
    "\n",
    "    for section, text in texts_di.items():\n",
    "        body += section\n",
    "        body += \"\\n\\n\"\n",
    "        body += text\n",
    "        body += \"\\n\\n\"\n",
    "    \n",
    "    return body\n",
    "\n",
    "def format_bib(bibs):\n",
    "    if type(bibs) == dict:\n",
    "        bibs = list(bibs.values())\n",
    "    bibs = deepcopy(bibs)\n",
    "    formatted = []\n",
    "    \n",
    "    for bib in bibs:\n",
    "        bib['authors'] = format_authors(\n",
    "            bib['authors'], \n",
    "            with_affiliation=False\n",
    "        )\n",
    "        formatted_ls = [str(bib[k]) for k in ['title', 'authors', 'venue', 'year']]\n",
    "        formatted.append(\", \".join(formatted_ls))\n",
    "    \n",
    "    return \"; \".join(formatted)\n",
    "\n",
    "def load_files(dirname):\n",
    "    filenames = os.listdir(dirname)\n",
    "    raw_files = []\n",
    "\n",
    "    for filename in tqdm(filenames):\n",
    "        filename = dirname + filename\n",
    "        file = json.load(open(filename, 'rb'))\n",
    "        raw_files.append(file)\n",
    "    \n",
    "    return raw_files\n",
    "\n",
    "def generate_clean_df(all_files):\n",
    "    cleaned_files = []\n",
    "    \n",
    "    for file in tqdm(all_files):\n",
    "        features = [\n",
    "            file['paper_id'],\n",
    "            file['metadata']['title'],\n",
    "            format_authors(file['metadata']['authors']),\n",
    "            format_authors(file['metadata']['authors'], \n",
    "                           with_affiliation=True),\n",
    "            format_body(file['abstract']),\n",
    "            format_body(file['body_text']),\n",
    "            format_bib(file['bib_entries']),\n",
    "            file['metadata']['authors'],\n",
    "            file['bib_entries']\n",
    "        ]\n",
    "\n",
    "        cleaned_files.append(features)\n",
    "\n",
    "    col_names = ['paper_id', 'title', 'authors',\n",
    "                 'affiliations', 'abstract', 'text', \n",
    "                 'bibliography','raw_authors','raw_bibliography']\n",
    "\n",
    "    clean_df = pd.DataFrame(cleaned_files, columns=col_names)\n",
    "    clean_df = clean_df.drop(['raw_authors', 'raw_bibliography'], axis=1)\n",
    "    clean_df.head()\n",
    "    \n",
    "    return clean_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf235e5474414fcc9c4baf14ca688d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8756c9e91a1e4a9588540c642cff953c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(7120, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['title', 'authors', 'abstract'], dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cargamos Info\n",
    "pmc_dir = 'C:/Users/LENOVO/Documents/Maestría/Semestre I/Almacenamiento y Recuperacion de Informacion/Taller3/Script/jason_prueba/'\n",
    "pmc_files = load_files(pmc_dir)\n",
    "pmc_df = generate_clean_df(pmc_files)\n",
    "print(pmc_df.shape)\n",
    "del pmc_df['paper_id']\n",
    "del pmc_df['affiliations']\n",
    "del pmc_df['text']\n",
    "del pmc_df['bibliography']\n",
    "pmc_df.head()\n",
    "pmc_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare StopsWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "#stop_words1 = stopwords.words('spanish')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'Abstract', 'abstract', 'la', 'en', 'el', 'los', 'se', 'del', 'una', 'para', 'por', 'entre', 'e', 'fue', 'su', 'más', 'este'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Correlation between antimicrobial consumption ...</td>\n",
       "      <td>Chih-Cheng Lai, Chen-Chen Chu, Aristine Cheng,...</td>\n",
       "      <td>Abstract\\n\\nObjectives: This study was conduct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pneumonie virale sévère de l'immunocompétent V...</td>\n",
       "      <td>B Guery, T D&amp;apos;escrivan, H Georges, L Legou...</td>\n",
       "      <td>Abstract\\n\\nReçu et accepté le 7 février 2004L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microheterogeneity of S-glycoprotein of mouse ...</td>\n",
       "      <td>Emilia L Oleszaka, Keith Knisley, L Scott Rodk...</td>\n",
       "      <td>Abstract\\n\\nIEF, isoelectric focusing; NC, nit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domestic Cats as Laboratory Animals</td>\n",
       "      <td>Brenda Griffin, Henry J Baker</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bestatin-mediated inhibition of leucine aminop...</td>\n",
       "      <td>Gabriel Pulido-Cejudo, Brian Conway, Pierre Pr...</td>\n",
       "      <td>Abstract\\n\\nBestatin, an inhibitor of leucine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Correlation between antimicrobial consumption ...   \n",
       "1  Pneumonie virale sévère de l'immunocompétent V...   \n",
       "2  Microheterogeneity of S-glycoprotein of mouse ...   \n",
       "3                Domestic Cats as Laboratory Animals   \n",
       "4  Bestatin-mediated inhibition of leucine aminop...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Chih-Cheng Lai, Chen-Chen Chu, Aristine Cheng,...   \n",
       "1  B Guery, T D&apos;escrivan, H Georges, L Legou...   \n",
       "2  Emilia L Oleszaka, Keith Knisley, L Scott Rodk...   \n",
       "3                      Brenda Griffin, Henry J Baker   \n",
       "4  Gabriel Pulido-Cejudo, Brian Conway, Pierre Pr...   \n",
       "\n",
       "                                            abstract  \n",
       "0  Abstract\\n\\nObjectives: This study was conduct...  \n",
       "1  Abstract\\n\\nReçu et accepté le 7 février 2004L...  \n",
       "2  Abstract\\n\\nIEF, isoelectric focusing; NC, nit...  \n",
       "3                                                     \n",
       "4  Abstract\\n\\nBestatin, an inhibitor of leucine ...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove new line characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = pmc_df.abstract.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abstract Objectives: This study was conducted to investigate the correlation between antibiotic consumption and the incidence of health-care-associated infections (HCAIs) caused by methicillin-resistant Staphylococcus aureus (MRSA) (HCAI-MRSA) and vancomycin-resistant enterococci (VREs) (HCAI-VREs) at a university hospital in Taiwan during the period from 2000 to 2010. Methods: Data on annual patient-days and annual consumption (defined daily dose/1000 patient-days) of glycopeptides (vancomycin and teicoplanin), linezolid, fusidic acid, tigecycline, and daptomycin were analyzed. Yearly aggregated data on the number of nonduplicate clinical MRSA and VRE isolates causing HCAI were collected.Journal of Microbiology, Immunology and Infection (2015) 48, 431e436 aureus;Results: Overall, the consumption of teicoplanin and linezolid significantly increased during the study period. A significant decrease in the incidence of HCAI-MRSA and a significant increase in the incidence of HCAI-VRE were found during the study period. A significant correlation was found between the increased use of teicoplanin and linezolid and the decreased incidence of HCAI-MRSA. By contrast, positive correlations were found between the consumption of teicoplanin and tigecycline and the incidence of HCAI-VRE.Conclusion: This study identified various correlations between the consumption of antibiotics and the incidence of HCAI-MRSA and HCAI-VRE. Strict implementation of infection-control guidelines and reinforcement of administering appropriate antibiotic agents would be helpful in decreasing the incidence of MRSA and VRE in hospitals. ']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abstract Objectives: This study was conducted to investigate the correlation '\n",
      " 'between antibiotic consumption and the incidence of health-care-associated '\n",
      " 'infections (HCAIs) caused by methicillin-resistant Staphylococcus aureus '\n",
      " '(MRSA) (HCAI-MRSA) and vancomycin-resistant enterococci (VREs) (HCAI-VREs) '\n",
      " 'at a university hospital in Taiwan during the period from 2000 to 2010. '\n",
      " 'Methods: Data on annual patient-days and annual consumption (defined daily '\n",
      " 'dose/1000 patient-days) of glycopeptides (vancomycin and teicoplanin), '\n",
      " 'linezolid, fusidic acid, tigecycline, and daptomycin were analyzed. Yearly '\n",
      " 'aggregated data on the number of nonduplicate clinical MRSA and VRE isolates '\n",
      " 'causing HCAI were collected.Journal of Microbiology, Immunology and '\n",
      " 'Infection (2015) 48, 431e436 aureus;Results: Overall, the consumption of '\n",
      " 'teicoplanin and linezolid significantly increased during the study period. A '\n",
      " 'significant decrease in the incidence of HCAI-MRSA and a significant '\n",
      " 'increase in the incidence of HCAI-VRE were found during the study period. A '\n",
      " 'significant correlation was found between the increased use of teicoplanin '\n",
      " 'and linezolid and the decreased incidence of HCAI-MRSA. By contrast, '\n",
      " 'positive correlations were found between the consumption of teicoplanin and '\n",
      " 'tigecycline and the incidence of HCAI-VRE.Conclusion: This study identified '\n",
      " 'various correlations between the consumption of antibiotics and the '\n",
      " 'incidence of HCAI-MRSA and HCAI-VRE. Strict implementation of '\n",
      " 'infection-control guidelines and reinforcement of administering appropriate '\n",
      " 'antibiotic agents would be helpful in decreasing the incidence of MRSA and '\n",
      " 'VRE in hospitals. ']\n"
     ]
    }
   ],
   "source": [
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenized words & clean up text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['abstract', 'objectives', 'this', 'study', 'was', 'conducted', 'to', 'investigate', 'the', 'correlation', 'between', 'antibiotic', 'consumption', 'and', 'the', 'incidence', 'of', 'health', 'care', 'associated', 'infections', 'hcais', 'caused', 'by', 'methicillin', 'resistant', 'staphylococcus', 'aureus', 'mrsa', 'hcai', 'mrsa', 'and', 'vancomycin', 'resistant', 'enterococci', 'vres', 'hcai', 'vres', 'at', 'university', 'hospital', 'in', 'taiwan', 'during', 'the', 'period', 'from', 'to', 'methods', 'data', 'on', 'annual', 'patient', 'days', 'and', 'annual', 'consumption', 'defined', 'daily', 'dose', 'patient', 'days', 'of', 'glycopeptides', 'vancomycin', 'and', 'teicoplanin', 'linezolid', 'fusidic', 'acid', 'tigecycline', 'and', 'daptomycin', 'were', 'analyzed', 'yearly', 'aggregated', 'data', 'on', 'the', 'number', 'of', 'nonduplicate', 'clinical', 'mrsa', 'and', 'vre', 'isolates', 'causing', 'hcai', 'were', 'collected', 'journal', 'of', 'microbiology', 'immunology', 'and', 'infection', 'aureus', 'results', 'overall', 'the', 'consumption', 'of', 'teicoplanin', 'and', 'linezolid', 'significantly', 'increased', 'during', 'the', 'study', 'period', 'significant', 'decrease', 'in', 'the', 'incidence', 'of', 'hcai', 'mrsa', 'and', 'significant', 'increase', 'in', 'the', 'incidence', 'of', 'hcai', 'vre', 'were', 'found', 'during', 'the', 'study', 'period', 'significant', 'correlation', 'was', 'found', 'between', 'the', 'increased', 'use', 'of', 'teicoplanin', 'and', 'linezolid', 'and', 'the', 'decreased', 'incidence', 'of', 'hcai', 'mrsa', 'by', 'contrast', 'positive', 'correlations', 'were', 'found', 'between', 'the', 'consumption', 'of', 'teicoplanin', 'and', 'tigecycline', 'and', 'the', 'incidence', 'of', 'hcai', 'vre', 'conclusion', 'this', 'study', 'identified', 'various', 'correlations', 'between', 'the', 'consumption', 'of', 'antibiotics', 'and', 'the', 'incidence', 'of', 'hcai', 'mrsa', 'and', 'hcai', 'vre', 'strict', 'implementation', 'of', 'infection', 'control', 'guidelines', 'and', 'reinforcement', 'of', 'administering', 'appropriate', 'antibiotic', 'agents', 'would', 'be', 'helpful', 'in', 'decreasing', 'the', 'incidence', 'of', 'mrsa', 'and', 'vre', 'in', 'hospitals']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "data = list(sent_to_words(data))\n",
    "\n",
    "print(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating bigrams & trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data], threshold=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract', 'recu', 'et', 'accepte_le', 'fevrier', 'les', 'infections', 'virales', 'respiratoires', 'communautaires', 'sont', 'frequentes', 'et', 'le_plus_souvent', 'benignes', 'beaucoup', 'dagents', 'differents', 'comme', 'les', 'virus', 'influenza', 'ou', 'para', 'influenza', 'le', 'virus', 'respiratoire', 'syncitial', 'les', 'rhinovirus', 'coronavirus', 'adenovirus', 'et', 'les', 'herpes', 'virus', 'peuvent_etre', 'isoles', 'chez_les', 'patients', 'parmi', 'ces', 'virus', 'le', 'cytomegalovirus_cmv', 'peut_etre', 'responsable', 'de', 'pneumonie', 'nosocomiale', 'en', 'reanimation', 'le', 'diagnostic', 'des', 'infections', 'virales', 'est', 'difficile', 'car', 'les', 'signes', 'cliniques', 'sont', 'non', 'specifiques', 'et', 'lisolement', 'du', 'virus', 'responsable', 'difficile', 'cependant', 'une', 'symptomatologie', 'clinique', 'associant', 'fievre', 'myalgies', 'cephalees', 'pharyngite', 'est', 'frequente', 'dans_les', 'infections', 'inflenza', 'qui', 'peuvent', 'aboutir', 'des', 'tableaux', 'severes', 'enfin', 'le', 'virus', 'plus', 'recent', 'responsable', 'dinfection', 'respiratoire', 'est', 'un', 'virus', 'nouvellement', 'decouvert', 'de', 'la', 'famille', 'des', 'coronavirus', 'le', 'sras', 'cov', 'qui', 'ete', 'responsable', 'dune', 'epidemie', 'dinfections', 'respiratoires', 'severes', 'les', 'pneumonies', 'virales', 'sont', 'frequentes', 'mais', 'probablement', 'non', 'diagnostiquees', 'chez_les', 'patients', 'cependant', 'le', 'diagnostic', 'est', 'necessaire', 'car', 'pour', 'la', 'plupart_des', 'pathogenes', 'il', 'existe', 'un', 'traitement', 'efficace', 'le', 'diagnostic', 'repose_sur', 'lhistologie', 'mais', 'de', 'nouvelles', 'techniques', 'comme', 'la', 'pcr', 'doivent', 'devenir', 'dutilisation', 'courante', 'pour', 'ameliorer', 'le', 'rendement', 'diagnostique', 'societe', 'de', 'reanimation', 'de', 'langue', 'francaise', 'publie_par', 'elsevier_sas_tous_droits', 'reserves', 'respiratory', 'infections', 'are', 'frequently', 'encountered', 'in', 'the', 'community', 'these', 'infections', 'are', 'usually', 'associated', 'with', 'only', 'minor', 'consequences', 'many', 'different', 'agents', 'such', 'as', 'influenza', 'and', 'parainfluenza', 'virus', 'respiratory', 'syncitial', 'virus', 'rhinovirus', 'coronavirus', 'adenovirus', 'and', 'herpes', 'virus', 'can', 'be', 'found', 'in', 'immuno', 'competent', 'patients', 'among', 'these', 'pathogens', 'cytomegalovirus_cmv', 'has', 'been', 'found', 'to', 'be', 'responsible', 'for', 'nosocomial', 'pneumonia', 'in', 'icu', 'the', 'main', 'problem', 'for', 'viral', 'infections', 'is', 'the', 'diagnosis', 'isolation', 'of', 'the', 'pathogen', 'is', 'often', 'difficult', 'and', 'not', 'always', 'reliable', 'and', 'the', 'symptoms', 'not', 'specific', 'however', 'influenza', 'is', 'characterised', 'by', 'fever', 'myalgia', 'headache', 'and', 'pharyngitis', 'this', 'infection', 'may', 'be', 'very', 'mild', 'even', 'asymptomatic', 'moderate', 'or', 'very', 'severe', 'finally', 'the', 'most', 'recent', 'viral', 'pathogen', 'involved', 'in', 'respiratory', 'disease', 'is', 'newly_discovered', 'coronavirus', 'the', 'sars_cov', 'which', 'was', 'responsible', 'for', 'the', 'worldwide', 'outbreak', 'of', 'severe_acute_respiratory_syndrome', 'viral', 'pneumonia', 'is', 'common', 'pathology', 'which', 'is', 'probably', 'underdiagnosed', 'in', 'immuno', 'competent', 'patients', 'many', 'reports', 'show', 'that', 'even', 'if', 'the', 'diagnosis', 'is', 'difficult', 'to', 'obtain', 'it', 'is', 'not', 'useless', 'as', 'long', 'as', 'we', 'have', 'for', 'most', 'of', 'the', 'pathogens', 'an', 'effective', 'treatment', 'the', 'gold_standard', 'was', 'histology', 'new', 'techniques', 'like', 'pcr', 'can', 'probably', 'make', 'difference', 'and', 'should', 'be', 'included', 'in', 'the', 'guidelines', 'to', 'improve', 'diagnostic', 'efficiency', 'societe', 'de', 'reanimation', 'de', 'langue', 'francaise', 'publie_par', 'elsevier_sas_tous_droits', 'reserves']\n"
     ]
    }
   ],
   "source": [
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data[1]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords, make bigrams & lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recu',\n",
       " 'et',\n",
       " 'accepte',\n",
       " 'le',\n",
       " 'fevrier',\n",
       " 'les',\n",
       " 'infections',\n",
       " 'virales',\n",
       " 'respiratoires',\n",
       " 'communautaires',\n",
       " 'sont',\n",
       " 'frequentes',\n",
       " 'et',\n",
       " 'le',\n",
       " 'plus',\n",
       " 'souvent',\n",
       " 'benignes',\n",
       " 'beaucoup',\n",
       " 'dagents',\n",
       " 'differents',\n",
       " 'comme',\n",
       " 'les',\n",
       " 'virus',\n",
       " 'influenza',\n",
       " 'ou',\n",
       " 'influenza',\n",
       " 'le',\n",
       " 'virus',\n",
       " 'respiratoire',\n",
       " 'syncitial',\n",
       " 'les',\n",
       " 'rhinovirus',\n",
       " 'coronavirus',\n",
       " 'adenovirus',\n",
       " 'et',\n",
       " 'les',\n",
       " 'herpes',\n",
       " 'virus',\n",
       " 'peuvent',\n",
       " 'etre',\n",
       " 'isoles',\n",
       " 'chez',\n",
       " 'les',\n",
       " 'patients',\n",
       " 'parmi',\n",
       " 'ces',\n",
       " 'virus',\n",
       " 'le',\n",
       " 'cytomegalovirus',\n",
       " 'cmv',\n",
       " 'peut',\n",
       " 'etre',\n",
       " 'responsable',\n",
       " 'de',\n",
       " 'pneumonie',\n",
       " 'nosocomiale',\n",
       " 'reanimation',\n",
       " 'le',\n",
       " 'diagnostic',\n",
       " 'des',\n",
       " 'infections',\n",
       " 'virales',\n",
       " 'est',\n",
       " 'difficile',\n",
       " 'car',\n",
       " 'les',\n",
       " 'signes',\n",
       " 'cliniques',\n",
       " 'sont',\n",
       " 'non',\n",
       " 'specifiques',\n",
       " 'et',\n",
       " 'lisolement',\n",
       " 'du',\n",
       " 'virus',\n",
       " 'responsable',\n",
       " 'difficile',\n",
       " 'cependant',\n",
       " 'une',\n",
       " 'symptomatologie',\n",
       " 'clinique',\n",
       " 'associant',\n",
       " 'fievre',\n",
       " 'myalgies',\n",
       " 'cephalees',\n",
       " 'pharyngite',\n",
       " 'est',\n",
       " 'frequente',\n",
       " 'dans',\n",
       " 'les',\n",
       " 'infections',\n",
       " 'inflenza',\n",
       " 'qui',\n",
       " 'peuvent',\n",
       " 'aboutir',\n",
       " 'des',\n",
       " 'tableaux',\n",
       " 'severes',\n",
       " 'enfin',\n",
       " 'le',\n",
       " 'virus',\n",
       " 'plus',\n",
       " 'recent',\n",
       " 'responsable',\n",
       " 'dinfection',\n",
       " 'respiratoire',\n",
       " 'est',\n",
       " 'un',\n",
       " 'virus',\n",
       " 'nouvellement',\n",
       " 'decouvert',\n",
       " 'de',\n",
       " 'famille',\n",
       " 'des',\n",
       " 'coronavirus',\n",
       " 'le',\n",
       " 'sras',\n",
       " 'cov',\n",
       " 'qui',\n",
       " 'ete',\n",
       " 'responsable',\n",
       " 'dune',\n",
       " 'epidemie',\n",
       " 'dinfections',\n",
       " 'respiratoires',\n",
       " 'severes',\n",
       " 'les',\n",
       " 'pneumonies',\n",
       " 'virales',\n",
       " 'sont',\n",
       " 'frequentes',\n",
       " 'mais',\n",
       " 'probablement',\n",
       " 'non',\n",
       " 'diagnostiquees',\n",
       " 'chez',\n",
       " 'les',\n",
       " 'patients',\n",
       " 'cependant',\n",
       " 'le',\n",
       " 'diagnostic',\n",
       " 'est',\n",
       " 'necessaire',\n",
       " 'car',\n",
       " 'pour',\n",
       " 'plupart',\n",
       " 'des',\n",
       " 'pathogenes',\n",
       " 'il',\n",
       " 'existe',\n",
       " 'un',\n",
       " 'traitement',\n",
       " 'efficace',\n",
       " 'le',\n",
       " 'diagnostic',\n",
       " 'repose',\n",
       " 'sur',\n",
       " 'lhistologie',\n",
       " 'mais',\n",
       " 'de',\n",
       " 'nouvelles',\n",
       " 'techniques',\n",
       " 'comme',\n",
       " 'pcr',\n",
       " 'doivent',\n",
       " 'devenir',\n",
       " 'dutilisation',\n",
       " 'courante',\n",
       " 'pour',\n",
       " 'ameliorer',\n",
       " 'le',\n",
       " 'rendement',\n",
       " 'diagnostique',\n",
       " 'societe',\n",
       " 'de',\n",
       " 'reanimation',\n",
       " 'de',\n",
       " 'langue',\n",
       " 'francaise',\n",
       " 'publie',\n",
       " 'par',\n",
       " 'elsevier',\n",
       " 'sas',\n",
       " 'tous',\n",
       " 'droits',\n",
       " 'reserves',\n",
       " 'respiratory',\n",
       " 'infections',\n",
       " 'frequently',\n",
       " 'encountered',\n",
       " 'community',\n",
       " 'infections',\n",
       " 'usually',\n",
       " 'associated',\n",
       " 'minor',\n",
       " 'consequences',\n",
       " 'many',\n",
       " 'different',\n",
       " 'agents',\n",
       " 'influenza',\n",
       " 'parainfluenza',\n",
       " 'virus',\n",
       " 'respiratory',\n",
       " 'syncitial',\n",
       " 'virus',\n",
       " 'rhinovirus',\n",
       " 'coronavirus',\n",
       " 'adenovirus',\n",
       " 'herpes',\n",
       " 'virus',\n",
       " 'found',\n",
       " 'immuno',\n",
       " 'competent',\n",
       " 'patients',\n",
       " 'among',\n",
       " 'pathogens',\n",
       " 'cytomegalovirus',\n",
       " 'cmv',\n",
       " 'found',\n",
       " 'responsible',\n",
       " 'nosocomial',\n",
       " 'pneumonia',\n",
       " 'icu',\n",
       " 'main',\n",
       " 'problem',\n",
       " 'viral',\n",
       " 'infections',\n",
       " 'diagnosis',\n",
       " 'isolation',\n",
       " 'pathogen',\n",
       " 'often',\n",
       " 'difficult',\n",
       " 'always',\n",
       " 'reliable',\n",
       " 'symptoms',\n",
       " 'specific',\n",
       " 'however',\n",
       " 'influenza',\n",
       " 'characterised',\n",
       " 'fever',\n",
       " 'myalgia',\n",
       " 'headache',\n",
       " 'pharyngitis',\n",
       " 'infection',\n",
       " 'may',\n",
       " 'mild',\n",
       " 'even',\n",
       " 'asymptomatic',\n",
       " 'moderate',\n",
       " 'severe',\n",
       " 'finally',\n",
       " 'recent',\n",
       " 'viral',\n",
       " 'pathogen',\n",
       " 'involved',\n",
       " 'respiratory',\n",
       " 'disease',\n",
       " 'newly',\n",
       " 'discovered',\n",
       " 'coronavirus',\n",
       " 'sars',\n",
       " 'cov',\n",
       " 'responsible',\n",
       " 'worldwide',\n",
       " 'outbreak',\n",
       " 'severe',\n",
       " 'acute',\n",
       " 'respiratory',\n",
       " 'syndrome',\n",
       " 'viral',\n",
       " 'pneumonia',\n",
       " 'common',\n",
       " 'pathology',\n",
       " 'probably',\n",
       " 'underdiagnosed',\n",
       " 'immuno',\n",
       " 'competent',\n",
       " 'patients',\n",
       " 'many',\n",
       " 'reports',\n",
       " 'show',\n",
       " 'even',\n",
       " 'diagnosis',\n",
       " 'difficult',\n",
       " 'obtain',\n",
       " 'useless',\n",
       " 'long',\n",
       " 'pathogens',\n",
       " 'effective',\n",
       " 'treatment',\n",
       " 'gold',\n",
       " 'standard',\n",
       " 'histology',\n",
       " 'new',\n",
       " 'techniques',\n",
       " 'like',\n",
       " 'pcr',\n",
       " 'probably',\n",
       " 'make',\n",
       " 'difference',\n",
       " 'included',\n",
       " 'guidelines',\n",
       " 'improve',\n",
       " 'diagnostic',\n",
       " 'efficiency',\n",
       " 'societe',\n",
       " 'de',\n",
       " 'reanimation',\n",
       " 'de',\n",
       " 'langue',\n",
       " 'francaise',\n",
       " 'publie',\n",
       " 'par',\n",
       " 'elsevier',\n",
       " 'sas',\n",
       " 'tous',\n",
       " 'droits',\n",
       " 'reserves']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_nostops[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recu',\n",
       " 'et',\n",
       " 'accepte_le',\n",
       " 'fevrier',\n",
       " 'les',\n",
       " 'infections',\n",
       " 'virales',\n",
       " 'respiratoires',\n",
       " 'communautaires',\n",
       " 'sont',\n",
       " 'frequentes',\n",
       " 'et',\n",
       " 'le',\n",
       " 'plus_souvent',\n",
       " 'benignes',\n",
       " 'beaucoup',\n",
       " 'dagents',\n",
       " 'differents',\n",
       " 'comme',\n",
       " 'les',\n",
       " 'virus',\n",
       " 'influenza',\n",
       " 'ou',\n",
       " 'influenza',\n",
       " 'le',\n",
       " 'virus',\n",
       " 'respiratoire',\n",
       " 'syncitial',\n",
       " 'les',\n",
       " 'rhinovirus',\n",
       " 'coronavirus',\n",
       " 'adenovirus',\n",
       " 'et',\n",
       " 'les',\n",
       " 'herpes',\n",
       " 'virus',\n",
       " 'peuvent_etre',\n",
       " 'isoles',\n",
       " 'chez_les',\n",
       " 'patients',\n",
       " 'parmi',\n",
       " 'ces',\n",
       " 'virus',\n",
       " 'le',\n",
       " 'cytomegalovirus_cmv',\n",
       " 'peut_etre',\n",
       " 'responsable',\n",
       " 'de',\n",
       " 'pneumonie',\n",
       " 'nosocomiale',\n",
       " 'reanimation',\n",
       " 'le',\n",
       " 'diagnostic',\n",
       " 'des',\n",
       " 'infections',\n",
       " 'virales',\n",
       " 'est',\n",
       " 'difficile',\n",
       " 'car',\n",
       " 'les',\n",
       " 'signes',\n",
       " 'cliniques',\n",
       " 'sont',\n",
       " 'non',\n",
       " 'specifiques',\n",
       " 'et',\n",
       " 'lisolement',\n",
       " 'du',\n",
       " 'virus',\n",
       " 'responsable',\n",
       " 'difficile',\n",
       " 'cependant',\n",
       " 'une',\n",
       " 'symptomatologie',\n",
       " 'clinique',\n",
       " 'associant',\n",
       " 'fievre',\n",
       " 'myalgies',\n",
       " 'cephalees',\n",
       " 'pharyngite',\n",
       " 'est',\n",
       " 'frequente',\n",
       " 'dans_les',\n",
       " 'infections',\n",
       " 'inflenza',\n",
       " 'qui',\n",
       " 'peuvent',\n",
       " 'aboutir',\n",
       " 'des',\n",
       " 'tableaux',\n",
       " 'severes',\n",
       " 'enfin',\n",
       " 'le',\n",
       " 'virus',\n",
       " 'plus',\n",
       " 'recent',\n",
       " 'responsable',\n",
       " 'dinfection',\n",
       " 'respiratoire',\n",
       " 'est',\n",
       " 'un',\n",
       " 'virus',\n",
       " 'nouvellement',\n",
       " 'decouvert',\n",
       " 'de',\n",
       " 'famille',\n",
       " 'des',\n",
       " 'coronavirus',\n",
       " 'le',\n",
       " 'sras',\n",
       " 'cov',\n",
       " 'qui',\n",
       " 'ete',\n",
       " 'responsable',\n",
       " 'dune',\n",
       " 'epidemie',\n",
       " 'dinfections',\n",
       " 'respiratoires',\n",
       " 'severes',\n",
       " 'les',\n",
       " 'pneumonies',\n",
       " 'virales',\n",
       " 'sont',\n",
       " 'frequentes',\n",
       " 'mais',\n",
       " 'probablement',\n",
       " 'non',\n",
       " 'diagnostiquees',\n",
       " 'chez_les',\n",
       " 'patients',\n",
       " 'cependant',\n",
       " 'le',\n",
       " 'diagnostic',\n",
       " 'est',\n",
       " 'necessaire',\n",
       " 'car',\n",
       " 'pour',\n",
       " 'plupart_des',\n",
       " 'pathogenes',\n",
       " 'il',\n",
       " 'existe',\n",
       " 'un',\n",
       " 'traitement',\n",
       " 'efficace',\n",
       " 'le',\n",
       " 'diagnostic',\n",
       " 'repose_sur',\n",
       " 'lhistologie',\n",
       " 'mais',\n",
       " 'de',\n",
       " 'nouvelles',\n",
       " 'techniques',\n",
       " 'comme',\n",
       " 'pcr',\n",
       " 'doivent',\n",
       " 'devenir',\n",
       " 'dutilisation',\n",
       " 'courante',\n",
       " 'pour',\n",
       " 'ameliorer',\n",
       " 'le',\n",
       " 'rendement',\n",
       " 'diagnostique',\n",
       " 'societe',\n",
       " 'de',\n",
       " 'reanimation',\n",
       " 'de',\n",
       " 'langue',\n",
       " 'francaise',\n",
       " 'publie_par',\n",
       " 'elsevier_sas',\n",
       " 'tous_droits',\n",
       " 'reserves',\n",
       " 'respiratory',\n",
       " 'infections',\n",
       " 'frequently',\n",
       " 'encountered',\n",
       " 'community',\n",
       " 'infections',\n",
       " 'usually',\n",
       " 'associated',\n",
       " 'minor',\n",
       " 'consequences',\n",
       " 'many',\n",
       " 'different',\n",
       " 'agents',\n",
       " 'influenza',\n",
       " 'parainfluenza',\n",
       " 'virus',\n",
       " 'respiratory',\n",
       " 'syncitial',\n",
       " 'virus',\n",
       " 'rhinovirus',\n",
       " 'coronavirus',\n",
       " 'adenovirus',\n",
       " 'herpes',\n",
       " 'virus',\n",
       " 'found',\n",
       " 'immuno',\n",
       " 'competent',\n",
       " 'patients',\n",
       " 'among',\n",
       " 'pathogens',\n",
       " 'cytomegalovirus_cmv',\n",
       " 'found',\n",
       " 'responsible',\n",
       " 'nosocomial',\n",
       " 'pneumonia',\n",
       " 'icu',\n",
       " 'main',\n",
       " 'problem',\n",
       " 'viral',\n",
       " 'infections',\n",
       " 'diagnosis',\n",
       " 'isolation',\n",
       " 'pathogen',\n",
       " 'often',\n",
       " 'difficult',\n",
       " 'always',\n",
       " 'reliable',\n",
       " 'symptoms',\n",
       " 'specific',\n",
       " 'however',\n",
       " 'influenza',\n",
       " 'characterised',\n",
       " 'fever',\n",
       " 'myalgia',\n",
       " 'headache',\n",
       " 'pharyngitis',\n",
       " 'infection',\n",
       " 'may',\n",
       " 'mild',\n",
       " 'even',\n",
       " 'asymptomatic',\n",
       " 'moderate',\n",
       " 'severe',\n",
       " 'finally',\n",
       " 'recent',\n",
       " 'viral',\n",
       " 'pathogen',\n",
       " 'involved',\n",
       " 'respiratory',\n",
       " 'disease',\n",
       " 'newly_discovered',\n",
       " 'coronavirus',\n",
       " 'sars',\n",
       " 'cov',\n",
       " 'responsible',\n",
       " 'worldwide',\n",
       " 'outbreak',\n",
       " 'severe_acute',\n",
       " 'respiratory_syndrome',\n",
       " 'viral',\n",
       " 'pneumonia',\n",
       " 'common',\n",
       " 'pathology',\n",
       " 'probably',\n",
       " 'underdiagnosed',\n",
       " 'immuno',\n",
       " 'competent',\n",
       " 'patients',\n",
       " 'many',\n",
       " 'reports',\n",
       " 'show',\n",
       " 'even',\n",
       " 'diagnosis',\n",
       " 'difficult',\n",
       " 'obtain',\n",
       " 'useless',\n",
       " 'long',\n",
       " 'pathogens',\n",
       " 'effective',\n",
       " 'treatment',\n",
       " 'gold_standard',\n",
       " 'histology',\n",
       " 'new',\n",
       " 'techniques',\n",
       " 'like',\n",
       " 'pcr',\n",
       " 'probably',\n",
       " 'make',\n",
       " 'difference',\n",
       " 'included',\n",
       " 'guidelines',\n",
       " 'improve',\n",
       " 'diagnostic',\n",
       " 'efficiency',\n",
       " 'societe',\n",
       " 'de',\n",
       " 'reanimation',\n",
       " 'de',\n",
       " 'langue',\n",
       " 'francaise',\n",
       " 'publie_par',\n",
       " 'elsevier_sas',\n",
       " 'tous_droits',\n",
       " 'reserves']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_bigrams[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['objective',\n",
       "  'study',\n",
       "  'conduct',\n",
       "  'investigate',\n",
       "  'correlation',\n",
       "  'antibiotic',\n",
       "  'consumption',\n",
       "  'incidence',\n",
       "  'health',\n",
       "  'care',\n",
       "  'cause',\n",
       "  'resistant',\n",
       "  'resistant',\n",
       "  'vre',\n",
       "  'vre',\n",
       "  'university_hospital',\n",
       "  'period',\n",
       "  'method',\n",
       "  'data',\n",
       "  'annual',\n",
       "  'patient',\n",
       "  'day',\n",
       "  'annual',\n",
       "  'consumption',\n",
       "  'define',\n",
       "  'daily',\n",
       "  'dose',\n",
       "  'patient',\n",
       "  'day',\n",
       "  'glycopeptide',\n",
       "  'vancomycin',\n",
       "  'linezolid',\n",
       "  'fusidic',\n",
       "  'acid',\n",
       "  'tigecycline',\n",
       "  'daptomycin',\n",
       "  'analyze',\n",
       "  'yearly',\n",
       "  'aggregated',\n",
       "  'datum',\n",
       "  'mrsa',\n",
       "  'isolate',\n",
       "  'cause',\n",
       "  'collect',\n",
       "  'infection',\n",
       "  'result',\n",
       "  'overall',\n",
       "  'consumption',\n",
       "  'teicoplanin',\n",
       "  'significantly',\n",
       "  'increase',\n",
       "  'study',\n",
       "  'period',\n",
       "  'significant',\n",
       "  'decrease',\n",
       "  'incidence',\n",
       "  'mrsa',\n",
       "  'significant',\n",
       "  'increase',\n",
       "  'incidence',\n",
       "  'find',\n",
       "  'study',\n",
       "  'period',\n",
       "  'significant',\n",
       "  'correlation',\n",
       "  'find',\n",
       "  'increase',\n",
       "  'decrease',\n",
       "  'incidence',\n",
       "  'contrast',\n",
       "  'positive',\n",
       "  'correlation',\n",
       "  'find',\n",
       "  'consumption',\n",
       "  'teicoplanin',\n",
       "  'tigecycline',\n",
       "  'incidence',\n",
       "  'conclusion',\n",
       "  'study',\n",
       "  'identify',\n",
       "  'various',\n",
       "  'correlation',\n",
       "  'consumption',\n",
       "  'antibiotic',\n",
       "  'incidence',\n",
       "  'strict',\n",
       "  'implementation',\n",
       "  'infection',\n",
       "  'reinforcement',\n",
       "  'administer',\n",
       "  'appropriate',\n",
       "  'antibiotic',\n",
       "  'agent',\n",
       "  'would',\n",
       "  'helpful',\n",
       "  'decrease',\n",
       "  'incidence',\n",
       "  'mrsa',\n",
       "  'hospital']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lemmatized[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary & the corpus needed for topic modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Corpus\n",
    "texts = data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 3), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 5), (14, 1), (15, 4), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 3), (22, 1), (23, 1), (24, 3), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 7), (33, 3), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 3), (40, 1), (41, 1), (42, 2), (43, 3), (44, 1), (45, 1), (46, 2), (47, 1), (48, 3), (49, 1), (50, 1), (51, 4), (52, 2), (53, 2), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decrease'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('acid', 1),\n",
       "  ('administer', 1),\n",
       "  ('agent', 1),\n",
       "  ('aggregated', 1),\n",
       "  ('analyze', 1),\n",
       "  ('annual', 2),\n",
       "  ('antibiotic', 3),\n",
       "  ('appropriate', 1),\n",
       "  ('care', 1),\n",
       "  ('cause', 2),\n",
       "  ('collect', 1),\n",
       "  ('conclusion', 1),\n",
       "  ('conduct', 1),\n",
       "  ('consumption', 5),\n",
       "  ('contrast', 1),\n",
       "  ('correlation', 4),\n",
       "  ('daily', 1),\n",
       "  ('daptomycin', 1),\n",
       "  ('data', 1),\n",
       "  ('datum', 1),\n",
       "  ('day', 2),\n",
       "  ('decrease', 3),\n",
       "  ('define', 1),\n",
       "  ('dose', 1),\n",
       "  ('find', 3),\n",
       "  ('fusidic', 1),\n",
       "  ('glycopeptide', 1),\n",
       "  ('health', 1),\n",
       "  ('helpful', 1),\n",
       "  ('hospital', 1),\n",
       "  ('identify', 1),\n",
       "  ('implementation', 1),\n",
       "  ('incidence', 7),\n",
       "  ('increase', 3),\n",
       "  ('infection', 2),\n",
       "  ('investigate', 1),\n",
       "  ('isolate', 1),\n",
       "  ('linezolid', 1),\n",
       "  ('method', 1),\n",
       "  ('mrsa', 3),\n",
       "  ('objective', 1),\n",
       "  ('overall', 1),\n",
       "  ('patient', 2),\n",
       "  ('period', 3),\n",
       "  ('positive', 1),\n",
       "  ('reinforcement', 1),\n",
       "  ('resistant', 2),\n",
       "  ('result', 1),\n",
       "  ('significant', 3),\n",
       "  ('significantly', 1),\n",
       "  ('strict', 1),\n",
       "  ('study', 4),\n",
       "  ('teicoplanin', 2),\n",
       "  ('tigecycline', 2),\n",
       "  ('university_hospital', 1),\n",
       "  ('vancomycin', 1),\n",
       "  ('various', 1),\n",
       "  ('vre', 2),\n",
       "  ('would', 1),\n",
       "  ('yearly', 1)]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq)for id, freq in cp]for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the topics in LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.079*\"disease\" + 0.046*\"human\" + 0.043*\"respiratory\" + 0.034*\"new\" + '\n",
      "  '0.033*\"infectious\" + 0.027*\"cause\" + 0.024*\"development\" + '\n",
      "  '0.024*\"potential\" + 0.024*\"pathogen\" + 0.021*\"treatment\"'),\n",
      " (1,\n",
      "  '0.079*\"calf\" + 0.063*\"group\" + 0.061*\"day\" + 0.054*\"blood\" + 0.042*\"dose\" + '\n",
      "  '0.041*\"treat\" + 0.040*\"treatment\" + 0.035*\"concentration\" + 0.025*\"bovine\" '\n",
      "  '+ 0.022*\"diarrhea\"'),\n",
      " (2,\n",
      "  '0.039*\"specific\" + 0.037*\"antibody\" + 0.035*\"use\" + 0.027*\"isolate\" + '\n",
      "  '0.026*\"high\" + 0.022*\"show\" + 0.015*\"level\" + 0.014*\"indicate\" + '\n",
      "  '0.014*\"highly\" + 0.014*\"recombinant\"'),\n",
      " (3,\n",
      "  '0.156*\"health\" + 0.082*\"care\" + 0.058*\"global\" + 0.040*\"quality\" + '\n",
      "  '0.034*\"policy\" + 0.032*\"country\" + 0.030*\"threat\" + 0.026*\"hospital\" + '\n",
      "  '0.025*\"status\" + 0.021*\"medical\"'),\n",
      " (4,\n",
      "  '0.046*\"system\" + 0.038*\"base\" + 0.027*\"use\" + 0.025*\"provide\" + '\n",
      "  '0.018*\"design\" + 0.016*\"method\" + 0.016*\"include\" + 0.016*\"approach\" + '\n",
      "  '0.015*\"information\" + 0.015*\"research\"'),\n",
      " (5,\n",
      "  '0.097*\"virus\" + 0.079*\"cell\" + 0.051*\"viral\" + 0.042*\"infection\" + '\n",
      "  '0.024*\"response\" + 0.021*\"infect\" + 0.018*\"host\" + 0.018*\"mouse\" + '\n",
      "  '0.017*\"replication\" + 0.017*\"induce\"'),\n",
      " (6,\n",
      "  '0.274*\"activity\" + 0.125*\"compound\" + 0.104*\"antiviral\" + 0.044*\"anti\" + '\n",
      "  '0.040*\"image\" + 0.033*\"add\" + 0.026*\"excellent\" + 0.017*\"toxicity\" + '\n",
      "  '0.016*\"approve\" + 0.015*\"evaluate\"'),\n",
      " (7,\n",
      "  '0.133*\"assay\" + 0.130*\"respectively\" + 0.047*\"combination\" + 0.042*\"ensure\" '\n",
      "  '+ 0.036*\"induction\" + 0.034*\"recovery\" + 0.031*\"reliable\" + '\n",
      "  '0.024*\"optimize\" + 0.023*\"appearance\" + 0.021*\"persistent\"'),\n",
      " (8,\n",
      "  '0.119*\"pig\" + 0.076*\"mer\" + 0.074*\"ad\" + 0.065*\"score\" + '\n",
      "  '0.061*\"asymptomatic\" + 0.050*\"quarantine\" + 0.037*\"antimicrobial\" + '\n",
      "  '0.026*\"effectiveness\" + 0.024*\"commercial\" + 0.022*\"cohort\"'),\n",
      " (9,\n",
      "  '0.033*\"may\" + 0.027*\"factor\" + 0.025*\"also\" + 0.024*\"important\" + '\n",
      "  '0.021*\"different\" + 0.020*\"present\" + 0.016*\"role\" + 0.016*\"novel\" + '\n",
      "  '0.016*\"many\" + 0.016*\"relate\"'),\n",
      " (10,\n",
      "  '0.046*\"risk\" + 0.044*\"outbreak\" + 0.042*\"transmission\" + 0.039*\"spread\" + '\n",
      "  '0.030*\"epidemic\" + 0.029*\"impact\" + 0.024*\"case\" + 0.022*\"control\" + '\n",
      "  '0.021*\"number\" + 0.016*\"remain\"'),\n",
      " (11,\n",
      "  '0.066*\"analyse\" + 0.054*\"active\" + 0.054*\"direct\" + 0.037*\"mean\" + '\n",
      "  '0.034*\"free\" + 0.033*\"right\" + 0.032*\"equilibrium\" + 0.029*\"elsevi\" + '\n",
      "  '0.028*\"long\" + 0.028*\"form\"'),\n",
      " (12,\n",
      "  '0.064*\"specie\" + 0.042*\"illness\" + 0.041*\"aim\" + 0.030*\"profile\" + '\n",
      "  '0.026*\"innate\" + 0.025*\"potentially\" + 0.023*\"domestic\" + 0.020*\"oral\" + '\n",
      "  '0.020*\"promote\" + 0.018*\"mainly\"'),\n",
      " (13,\n",
      "  '0.110*\"technique\" + 0.070*\"survey\" + 0.052*\"currently\" + 0.049*\"selection\" '\n",
      "  '+ 0.045*\"optimal\" + 0.043*\"alternative\" + 0.038*\"conventional\" + '\n",
      "  '0.030*\"cattle\" + 0.028*\"decision_making\" + 0.027*\"subtype\"'),\n",
      " (14,\n",
      "  '0.173*\"vaccine\" + 0.127*\"strain\" + 0.027*\"vaccinate\" + 0.027*\"pedv\" + '\n",
      "  '0.026*\"protection\" + 0.023*\"frequency\" + 0.022*\"challenge\" + 0.021*\"titer\" '\n",
      "  '+ 0.019*\"elicit\" + 0.019*\"prepare\"'),\n",
      " (15,\n",
      "  '0.039*\"patient\" + 0.037*\"infection\" + 0.036*\"study\" + 0.030*\"result\" + '\n",
      "  '0.025*\"virus\" + 0.020*\"high\" + 0.020*\"test\" + 0.017*\"group\" + '\n",
      "  '0.017*\"detect\" + 0.016*\"sample\"'),\n",
      " (16,\n",
      "  '0.172*\"model\" + 0.047*\"phase\" + 0.038*\"furthermore\" + 0.033*\"particle\" + '\n",
      "  '0.030*\"propose\" + 0.028*\"air\" + 0.027*\"concentration\" + 0.025*\"ratio\" + '\n",
      "  '0.023*\"dynamic\" + 0.021*\"stress\"'),\n",
      " (17,\n",
      "  '0.264*\"interaction\" + 0.122*\"membrane\" + 0.070*\"transport\" + '\n",
      "  '0.047*\"attachment\" + 0.023*\"enrich\" + 0.021*\"density\" + 0.010*\"hypothesize\" '\n",
      "  '+ 0.007*\"thereby\" + 0.005*\"biophysical\" + 0.000*\"vector\"'),\n",
      " (18,\n",
      "  '0.198*\"entry\" + 0.181*\"cd\" + 0.006*\"portal\" + 0.000*\"vector\" + '\n",
      "  '0.000*\"utilize\" + 0.000*\"prrsv\" + 0.000*\"interact\" + 0.000*\"tropism\" + '\n",
      "  '0.000*\"gain\" + 0.000*\"greatly\"'),\n",
      " (19,\n",
      "  '0.142*\"protein\" + 0.048*\"sequence\" + 0.034*\"gene\" + 0.032*\"bind\" + '\n",
      "  '0.029*\"structure\" + 0.022*\"region\" + 0.021*\"genome\" + 0.021*\"domain\" + '\n",
      "  '0.019*\"site\" + 0.018*\"peptide\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the top ten Keywords in the topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute perplexity & coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -13.856865534234165\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.43366304210130213\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualize the topics keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis\n",
    "pyLDAvis.save_html(vis,'lda_visualization_Taller3.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LDA Mallet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "os.environ['MALLET_HOME'] = 'C:\\\\users\\\\LENOVO\\\\Downloads\\\\mallet-2.0.8'\n",
    "mallet_path = 'C:/Users/LENOVO/Downloads/mallet-2.0.8/bin/mallet'\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16,\n",
      "  [('strain', 0.05800094406419636),\n",
      "   ('isolate', 0.03953268822279915),\n",
      "   ('type', 0.03811659192825112),\n",
      "   ('study', 0.029206986075053103),\n",
      "   ('show', 0.026669813547321217),\n",
      "   ('result', 0.025194713240500353),\n",
      "   ('culture', 0.01646211942412084),\n",
      "   ('find', 0.014042954920934624),\n",
      "   ('pedv', 0.012980882700023602),\n",
      "   ('present', 0.011328770356384235)]),\n",
      " (12,\n",
      "  [('test', 0.05417864578169922),\n",
      "   ('sample', 0.04481015168038069),\n",
      "   ('detect', 0.03940715772776841),\n",
      "   ('detection', 0.035639932586497475),\n",
      "   ('positive', 0.03266580747496778),\n",
      "   ('method', 0.028353326063249727),\n",
      "   ('result', 0.022950332110637454),\n",
      "   ('assay', 0.02146326955487261),\n",
      "   ('clinical', 0.019133538217507684),\n",
      "   ('develop', 0.017943888172895807)]),\n",
      " (3,\n",
      "  [('sequence', 0.05813270698766882),\n",
      "   ('gene', 0.05743874446164522),\n",
      "   ('region', 0.027064538514920196),\n",
      "   ('genome', 0.02535632306624673),\n",
      "   ('identify', 0.01633481022794),\n",
      "   ('analysis', 0.01569422943468745),\n",
      "   ('mutation', 0.012918379330593071),\n",
      "   ('reveal', 0.0113169273474617),\n",
      "   ('suggest', 0.01030267442481183),\n",
      "   ('coronaviruse', 0.00928842150216196)]),\n",
      " (15,\n",
      "  [('patient', 0.10148254423720708),\n",
      "   ('clinical', 0.029411764705882353),\n",
      "   ('day', 0.01912960306073649),\n",
      "   ('treatment', 0.01831659493065519),\n",
      "   ('symptom', 0.013151602104256336),\n",
      "   ('outcome', 0.013055954088952654),\n",
      "   ('case', 0.012673362027737924),\n",
      "   ('group', 0.011621233859397418),\n",
      "   ('include', 0.01133428981348637),\n",
      "   ('therapy', 0.01133428981348637)]),\n",
      " (10,\n",
      "  [('health', 0.03146339355173308),\n",
      "   ('care', 0.01983749675857896),\n",
      "   ('management', 0.013052122050306855),\n",
      "   ('risk', 0.012447056789696603),\n",
      "   ('hospital', 0.012101305212205031),\n",
      "   ('practice', 0.010415766271933616),\n",
      "   ('medical', 0.008946322067594433),\n",
      "   ('conduct', 0.008643789437289308),\n",
      "   ('community', 0.007995505229492609),\n",
      "   ('policy', 0.007995505229492609)]),\n",
      " (9,\n",
      "  [('model', 0.06275687638318052),\n",
      "   ('individual', 0.021762040257139847),\n",
      "   ('network', 0.02023395510591211),\n",
      "   ('datum', 0.01723047739487828),\n",
      "   ('time', 0.01601854779218042),\n",
      "   ('number', 0.014543155232374328),\n",
      "   ('propose', 0.01370007376962799),\n",
      "   ('dynamic', 0.01343661081251976),\n",
      "   ('spread', 0.013015070081146591),\n",
      "   ('epidemic', 0.01138159974707556)]),\n",
      " (0,\n",
      "  [('human', 0.05669943093636834),\n",
      "   ('host', 0.03621314019658562),\n",
      "   ('important', 0.0239524055871702),\n",
      "   ('provide', 0.021055354371443354),\n",
      "   ('review', 0.019192964304190378),\n",
      "   ('mechanism', 0.019037765131919297),\n",
      "   ('recent', 0.018882565959648216),\n",
      "   ('role', 0.018727366787377134),\n",
      "   ('animal', 0.017640972581479564),\n",
      "   ('include', 0.016088980858768753)]),\n",
      " (1,\n",
      "  [('base', 0.03574509381065344),\n",
      "   ('method', 0.025285745093810652),\n",
      "   ('include', 0.02129609661419021),\n",
      "   ('information', 0.02021781324131982),\n",
      "   ('system', 0.01892387319387535),\n",
      "   ('application', 0.018115160664222557),\n",
      "   ('datum', 0.017683847315074403),\n",
      "   ('study', 0.016174250593055856),\n",
      "   ('describe', 0.014772482208324347),\n",
      "   ('provide', 0.013586370498166918)]),\n",
      " (11,\n",
      "  [('virus', 0.31435615181745213),\n",
      "   ('viral', 0.14505217291595002),\n",
      "   ('infection', 0.12446967090929939),\n",
      "   ('replication', 0.03927301914918014),\n",
      "   ('infect', 0.0318770783167068),\n",
      "   ('prrsv', 0.01708519665176012),\n",
      "   ('coronaviruse', 0.009345258571264763),\n",
      "   ('viruse', 0.00768260520582502),\n",
      "   ('load', 0.007338607957803004),\n",
      "   ('infected', 0.0072812750831326685)]),\n",
      " (13,\n",
      "  [('disease', 0.03162191686310585),\n",
      "   ('tissue', 0.02161789225550509),\n",
      "   ('cat', 0.020008049215201516),\n",
      "   ('lung', 0.018398206174897947),\n",
      "   ('mouse', 0.01805323980911861),\n",
      "   ('feline', 0.012591272350945783),\n",
      "   ('inflammatory', 0.01218881159086989),\n",
      "   ('acute', 0.011671362042200886),\n",
      "   ('lesion', 0.01115391249353188),\n",
      "   ('immune', 0.010808946127752544)])]\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.5205314384222818\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal number of topics for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to find the optimal numbers of topics for LDA\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.4314\n",
      "Num Topics = 8  has Coherence Value of 0.5117\n",
      "Num Topics = 14  has Coherence Value of 0.5295\n",
      "Num Topics = 20  has Coherence Value of 0.542\n",
      "Num Topics = 26  has Coherence Value of 0.5362\n",
      "Num Topics = 32  has Coherence Value of 0.5326\n",
      "Num Topics = 38  has Coherence Value of 0.517\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.048*\"test\" + 0.035*\"detection\" + 0.030*\"sample\" + 0.029*\"method\" + '\n",
      "  '0.022*\"detect\" + 0.020*\"assay\" + 0.016*\"develop\" + 0.016*\"diagnostic\" + '\n",
      "  '0.015*\"clinical\" + 0.015*\"positive\"'),\n",
      " (1,\n",
      "  '0.071*\"study\" + 0.062*\"result\" + 0.060*\"high\" + 0.055*\"level\" + '\n",
      "  '0.048*\"increase\" + 0.032*\"show\" + 0.031*\"compare\" + 0.031*\"significantly\" + '\n",
      "  '0.025*\"low\" + 0.022*\"significant\"'),\n",
      " (2,\n",
      "  '0.028*\"health\" + 0.024*\"care\" + 0.015*\"hospital\" + 0.012*\"management\" + '\n",
      "  '0.012*\"risk\" + 0.011*\"practice\" + 0.011*\"medical\" + 0.010*\"conduct\" + '\n",
      "  '0.009*\"measure\" + 0.009*\"conclusion\"'),\n",
      " (3,\n",
      "  '0.102*\"disease\" + 0.050*\"infectious\" + 0.027*\"population\" + 0.026*\"risk\" + '\n",
      "  '0.026*\"emerge\" + 0.026*\"outbreak\" + 0.016*\"country\" + 0.015*\"transmission\" '\n",
      "  '+ 0.014*\"pathogen\" + 0.012*\"control\"'),\n",
      " (4,\n",
      "  '0.055*\"model\" + 0.023*\"case\" + 0.021*\"number\" + 0.019*\"network\" + '\n",
      "  '0.017*\"epidemic\" + 0.016*\"transmission\" + 0.014*\"estimate\" + 0.013*\"time\" + '\n",
      "  '0.013*\"rate\" + 0.012*\"spread\"'),\n",
      " (5,\n",
      "  '0.153*\"cell\" + 0.036*\"expression\" + 0.035*\"infection\" + 0.031*\"induce\" + '\n",
      "  '0.024*\"response\" + 0.018*\"cd\" + 0.014*\"mouse\" + 0.014*\"receptor\" + '\n",
      "  '0.012*\"immune\" + 0.010*\"activation\"'),\n",
      " (6,\n",
      "  '0.053*\"report\" + 0.041*\"study\" + 0.032*\"form\" + 0.028*\"present\" + '\n",
      "  '0.025*\"active\" + 0.022*\"long\" + 0.021*\"analyse\" + 0.021*\"free\" + '\n",
      "  '0.018*\"type\" + 0.018*\"result\"'),\n",
      " (7,\n",
      "  '0.094*\"patient\" + 0.020*\"clinical\" + 0.020*\"acute\" + 0.019*\"case\" + '\n",
      "  '0.019*\"treatment\" + 0.013*\"day\" + 0.011*\"outcome\" + 0.011*\"severe\" + '\n",
      "  '0.011*\"lung\" + 0.011*\"symptom\"'),\n",
      " (8,\n",
      "  '0.049*\"group\" + 0.040*\"calf\" + 0.034*\"day\" + 0.019*\"control\" + '\n",
      "  '0.018*\"study\" + 0.014*\"age\" + 0.013*\"dog\" + 0.013*\"week\" + 0.012*\"animal\" + '\n",
      "  '0.012*\"high\"'),\n",
      " (9,\n",
      "  '0.161*\"protein\" + 0.031*\"bind\" + 0.026*\"structure\" + 0.022*\"peptide\" + '\n",
      "  '0.021*\"domain\" + 0.016*\"structural\" + 0.016*\"fusion\" + 0.015*\"site\" + '\n",
      "  '0.013*\"express\" + 0.012*\"residue\"'),\n",
      " (10,\n",
      "  '0.017*\"research\" + 0.016*\"approach\" + 0.014*\"development\" + 0.012*\"impact\" '\n",
      "  '+ 0.012*\"change\" + 0.011*\"make\" + 0.010*\"paper\" + 0.009*\"problem\" + '\n",
      "  '0.009*\"policy\" + 0.008*\"provide\"'),\n",
      " (11,\n",
      "  '0.066*\"system\" + 0.047*\"base\" + 0.037*\"study\" + 0.031*\"datum\" + '\n",
      "  '0.028*\"information\" + 0.028*\"method\" + 0.023*\"design\" + 0.018*\"describe\" + '\n",
      "  '0.016*\"identify\" + 0.015*\"require\"'),\n",
      " (12,\n",
      "  '0.061*\"activity\" + 0.050*\"viral\" + 0.039*\"replication\" + 0.037*\"antiviral\" '\n",
      "  '+ 0.034*\"virus\" + 0.033*\"target\" + 0.024*\"inhibit\" + 0.020*\"drug\" + '\n",
      "  '0.019*\"compound\" + 0.019*\"show\"'),\n",
      " (13,\n",
      "  '0.036*\"role\" + 0.030*\"function\" + 0.030*\"host\" + 0.027*\"viral\" + '\n",
      "  '0.022*\"mechanism\" + 0.018*\"involve\" + 0.018*\"process\" + 0.018*\"cellular\" + '\n",
      "  '0.017*\"complex\" + 0.017*\"interaction\"'),\n",
      " (14,\n",
      "  '0.064*\"gene\" + 0.057*\"sequence\" + 0.025*\"genome\" + 0.020*\"region\" + '\n",
      "  '0.020*\"strain\" + 0.018*\"analysis\" + 0.015*\"identify\" + 0.013*\"isolate\" + '\n",
      "  '0.013*\"mutation\" + 0.012*\"reveal\"'),\n",
      " (15,\n",
      "  '0.076*\"vaccine\" + 0.044*\"antibody\" + 0.034*\"specific\" + 0.031*\"response\" + '\n",
      "  '0.018*\"mouse\" + 0.016*\"vector\" + 0.015*\"vaccination\" + 0.015*\"recombinant\" '\n",
      "  '+ 0.014*\"immune\" + 0.014*\"effective\"'),\n",
      " (16,\n",
      "  '0.036*\"treatment\" + 0.032*\"effect\" + 0.021*\"concentration\" + 0.016*\"reduce\" '\n",
      "  '+ 0.013*\"high\" + 0.013*\"production\" + 0.012*\"product\" + 0.011*\"result\" + '\n",
      "  '0.011*\"efficiency\" + 0.011*\"reduction\"'),\n",
      " (17,\n",
      "  '0.070*\"human\" + 0.032*\"review\" + 0.025*\"provide\" + 0.022*\"potential\" + '\n",
      "  '0.022*\"agent\" + 0.022*\"therapeutic\" + 0.022*\"animal\" + 0.016*\"discuss\" + '\n",
      "  '0.015*\"development\" + 0.015*\"recent\"'),\n",
      " (18,\n",
      "  '0.204*\"virus\" + 0.041*\"infect\" + 0.039*\"infection\" + 0.034*\"strain\" + '\n",
      "  '0.023*\"show\" + 0.022*\"type\" + 0.018*\"pig\" + 0.018*\"isolate\" + 0.016*\"prrsv\" '\n",
      "  '+ 0.012*\"detect\"'),\n",
      " (19,\n",
      "  '0.103*\"infection\" + 0.056*\"virus\" + 0.049*\"respiratory\" + 0.044*\"viral\" + '\n",
      "  '0.028*\"child\" + 0.021*\"associate\" + 0.020*\"positive\" + 0.019*\"detect\" + '\n",
      "  '0.017*\"influenza\" + 0.015*\"identify\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the dominant topic in aech sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "   # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords'] \n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>study, result, high, level, increase, show, co...</td>\n",
       "      <td>[abstract, objectives, this, study, was, condu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3004</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>[abstract, recu, et, accepte, le, fevrier, les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>group, calf, day, control, study, age, dog, we...</td>\n",
       "      <td>[abstract, ief, isoelectric, focusing, nc, nit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>study, result, high, level, increase, show, co...</td>\n",
       "      <td>[abstract, bestatin, an, inhibitor, of, leucin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>model, case, number, network, epidemic, transm...</td>\n",
       "      <td>[abstract, breathing, is, high, risk, behavior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>infection, virus, respiratory, viral, child, a...</td>\n",
       "      <td>[abstract, background, human, coronavirus, nl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3517</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>[abstract, loop, mediated, isothermal, amplifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2621</td>\n",
       "      <td>protein, bind, structure, peptide, domain, str...</td>\n",
       "      <td>[abstract, the, spike, protein, of, porcine, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>model, case, number, network, epidemic, transm...</td>\n",
       "      <td>[abstract, during, outbreaks, of, communicable...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             1.0              0.1845   \n",
       "1            1             0.0              0.3004   \n",
       "2            2             8.0              0.0730   \n",
       "3            3             0.0              0.0500   \n",
       "4            4             1.0              0.2112   \n",
       "5            5             4.0              0.4477   \n",
       "6            6            19.0              0.1291   \n",
       "7            7             0.0              0.3517   \n",
       "8            8             9.0              0.2621   \n",
       "9            9             4.0              0.2975   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  study, result, high, level, increase, show, co...   \n",
       "1  test, detection, sample, method, detect, assay...   \n",
       "2  group, calf, day, control, study, age, dog, we...   \n",
       "3  test, detection, sample, method, detect, assay...   \n",
       "4  study, result, high, level, increase, show, co...   \n",
       "5  model, case, number, network, epidemic, transm...   \n",
       "6  infection, virus, respiratory, viral, child, a...   \n",
       "7  test, detection, sample, method, detect, assay...   \n",
       "8  protein, bind, structure, peptide, domain, str...   \n",
       "9  model, case, number, network, epidemic, transm...   \n",
       "\n",
       "                                                Text  \n",
       "0  [abstract, objectives, this, study, was, condu...  \n",
       "1  [abstract, recu, et, accepte, le, fevrier, les...  \n",
       "2  [abstract, ief, isoelectric, focusing, nc, nit...  \n",
       "3                                                 []  \n",
       "4  [abstract, bestatin, an, inhibitor, of, leucin...  \n",
       "5  [abstract, breathing, is, high, risk, behavior...  \n",
       "6  [abstract, background, human, coronavirus, nl,...  \n",
       "7  [abstract, loop, mediated, isothermal, amplifi...  \n",
       "8  [abstract, the, spike, protein, of, porcine, e...  \n",
       "9  [abstract, during, outbreaks, of, communicable...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most representaive document for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6314</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>[abstract, publicly, funded, repositories, suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3657</td>\n",
       "      <td>study, result, high, level, increase, show, co...</td>\n",
       "      <td>[abstract, background, previous, pharmaco, epi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>health, care, hospital, management, risk, prac...</td>\n",
       "      <td>[abstract, background, inclusion, of, reusable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>disease, infectious, population, risk, emerge,...</td>\n",
       "      <td>[abstract, zoonotic, diseases, cause, millions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5547</td>\n",
       "      <td>model, case, number, network, epidemic, transm...</td>\n",
       "      <td>[abstract, to, demonstrate, the, differences, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.6314   \n",
       "1        1.0              0.3657   \n",
       "2        2.0              0.4870   \n",
       "3        3.0              0.4474   \n",
       "4        4.0              0.5547   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  test, detection, sample, method, detect, assay...   \n",
       "1  study, result, high, level, increase, show, co...   \n",
       "2  health, care, hospital, management, risk, prac...   \n",
       "3  disease, infectious, population, risk, emerge,...   \n",
       "4  model, case, number, network, epidemic, transm...   \n",
       "\n",
       "                                                Text  \n",
       "0  [abstract, publicly, funded, repositories, suc...  \n",
       "1  [abstract, background, previous, pharmaco, epi...  \n",
       "2  [abstract, background, inclusion, of, reusable...  \n",
       "3  [abstract, zoonotic, diseases, cause, millions...  \n",
       "4  [abstract, to, demonstrate, the, differences, ...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic distribution across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>study, result, high, level, increase, show, co...</td>\n",
       "      <td>2781.0</td>\n",
       "      <td>0.3906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>group, calf, day, control, study, age, dog, we...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>study, result, high, level, increase, show, co...</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>model, case, number, network, epidemic, transm...</td>\n",
       "      <td>332.0</td>\n",
       "      <td>0.0466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>infection, virus, respiratory, viral, child, a...</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.0410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>protein, bind, structure, peptide, domain, str...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>model, case, number, network, epidemic, transm...</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0.0545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>cell, expression, infection, induce, response,...</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>vaccine, antibody, specific, response, mouse, ...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>vaccine, antibody, specific, response, mouse, ...</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.0333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>human, review, provide, potential, agent, ther...</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.0383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>cell, expression, infection, induce, response,...</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>protein, bind, structure, peptide, domain, str...</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test, detection, sample, method, detect, assay...</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.0372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dominant_Topic                                     Topic_Keywords  \\\n",
       "0.0              1.0  study, result, high, level, increase, show, co...   \n",
       "1.0              0.0  test, detection, sample, method, detect, assay...   \n",
       "2.0              8.0  group, calf, day, control, study, age, dog, we...   \n",
       "3.0              0.0  test, detection, sample, method, detect, assay...   \n",
       "4.0              1.0  study, result, high, level, increase, show, co...   \n",
       "5.0              4.0  model, case, number, network, epidemic, transm...   \n",
       "6.0             19.0  infection, virus, respiratory, viral, child, a...   \n",
       "7.0              0.0  test, detection, sample, method, detect, assay...   \n",
       "8.0              9.0  protein, bind, structure, peptide, domain, str...   \n",
       "9.0              4.0  model, case, number, network, epidemic, transm...   \n",
       "10.0             5.0  cell, expression, infection, induce, response,...   \n",
       "11.0            15.0  vaccine, antibody, specific, response, mouse, ...   \n",
       "12.0             0.0  test, detection, sample, method, detect, assay...   \n",
       "13.0            15.0  vaccine, antibody, specific, response, mouse, ...   \n",
       "14.0            17.0  human, review, provide, potential, agent, ther...   \n",
       "15.0             0.0  test, detection, sample, method, detect, assay...   \n",
       "16.0             5.0  cell, expression, infection, induce, response,...   \n",
       "17.0             9.0  protein, bind, structure, peptide, domain, str...   \n",
       "18.0             0.0  test, detection, sample, method, detect, assay...   \n",
       "19.0             0.0  test, detection, sample, method, detect, assay...   \n",
       "\n",
       "      Num_Documents  Perc_Documents  \n",
       "0.0          2781.0          0.3906  \n",
       "1.0            69.0          0.0097  \n",
       "2.0           289.0          0.0406  \n",
       "3.0           210.0          0.0295  \n",
       "4.0           242.0          0.0340  \n",
       "5.0           332.0          0.0466  \n",
       "6.0           159.0          0.0223  \n",
       "7.0           292.0          0.0410  \n",
       "8.0           198.0          0.0278  \n",
       "9.0           388.0          0.0545  \n",
       "10.0          224.0          0.0315  \n",
       "11.0           67.0          0.0094  \n",
       "12.0          264.0          0.0371  \n",
       "13.0          237.0          0.0333  \n",
       "14.0          268.0          0.0376  \n",
       "15.0          273.0          0.0383  \n",
       "16.0          164.0          0.0230  \n",
       "17.0          193.0          0.0271  \n",
       "18.0          205.0          0.0288  \n",
       "19.0          265.0          0.0372  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "# Show\n",
    "df_dominant_topics[:19]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
